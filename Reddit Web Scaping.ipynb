{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acbc2873",
   "metadata": {},
   "source": [
    "### Import Necessary Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9694dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from praw.models import MoreComments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dff89f0",
   "metadata": {},
   "source": [
    "### Scraping Reddit Subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcfd3efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this case, we only need to scrape pubilic information on the subreddit.\n",
    "#Read-only instance\n",
    "client_id = 'picc1mNrisHehkvl9Q-quA'\n",
    "client_secret = 'GB0xd8R6CFI-cp7UcSm0D6Msl1P6ow'\n",
    "user_agent = 'project_api'\n",
    "\n",
    "\n",
    "reddit_read_only = praw.Reddit(client_id = client_id,\n",
    "                              client_secret = client_secret,\n",
    "                              user_agent = user_agent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ead935bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news\n"
     ]
    }
   ],
   "source": [
    "# Ask user the subreddit they are interested.\n",
    "subreddit = input(\"Please type the name of the subreddit you are interested in: \")\n",
    "print(subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3e93a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display Name: news\n",
      "Title: News\n"
     ]
    }
   ],
   "source": [
    "subred = reddit_read_only.subreddit(subreddit)\n",
    "\n",
    "# Display the name of the Subreddit\n",
    "print(\"Display Name:\", subred.display_name)\n",
    " \n",
    "# Display the title of the Subreddit\n",
    "print(\"Title:\", subred.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8da21e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1946/1063938376.py:2: DeprecationWarning: Positional arguments for 'BaseListingMixin.top' will no longer be supported in PRAW 8.\n",
      "Call this function with 'time_filter' as a keyword argument.\n",
      "  posts = subred.top(\"week\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York sues Donald Trump, company and family members over widespread fraud claims, seeks at least $250 million in penalties\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TLDR: \\n\\n+ Civil Suit\\n+ Alleges Trump of fra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;\\tMar-a-Lago \"generated less than $25 million...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I don’t quite understand how someone can be af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The same people who stole money from cancer ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And this is how he'll be forced to admit he's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>This mofo told people his apartment is worth T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Everyone but Tiffany. You go girl.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>I'm starting to get the feeling this Trump Fam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Best hands free orgasm I've ever had</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>I’m shocked.  The guy who is a known grifter a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comment\n",
       "0   TLDR: \\n\\n+ Civil Suit\\n+ Alleges Trump of fra...\n",
       "1   >\\tMar-a-Lago \"generated less than $25 million...\n",
       "2   I don’t quite understand how someone can be af...\n",
       "3   The same people who stole money from cancer ch...\n",
       "4   And this is how he'll be forced to admit he's ...\n",
       "..                                                ...\n",
       "80  This mofo told people his apartment is worth T...\n",
       "81                 Everyone but Tiffany. You go girl.\n",
       "82  I'm starting to get the feeling this Trump Fam...\n",
       "83               Best hands free orgasm I've ever had\n",
       "84  I’m shocked.  The guy who is a known grifter a...\n",
       "\n",
       "[85 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract top voted posts from the news subreddit of this week.\n",
    "posts = subred.top(\"week\")\n",
    "\n",
    "# Let's expolore the first top voted post from the subreddit and extract the best comments from it.\n",
    "#First we need the url of the post.\n",
    "firstPost = next(posts)\n",
    "post_name=firstPost.title\n",
    "print(post_name)\n",
    "#create submission object\n",
    "submission = reddit_read_only.submission(firstPost)\n",
    "\n",
    "comments = []\n",
    "\n",
    "for comment in submission.comments:\n",
    "    if type(comment) == MoreComments:\n",
    "        continue\n",
    "    comments.append(comment.body)\n",
    "\n",
    "# save the list as a dataframe\n",
    "comments_df = pd.DataFrame(comments,columns=['comment'])\n",
    "comments_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0e8600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting data to a csv file.\n",
    "comments_df.to_csv(post_name+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec09555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('redditProject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a57e3824fba0a117152c644778be39002ac47d5f16a0be86b135f8643d52bfd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
